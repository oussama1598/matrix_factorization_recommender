{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row, SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/01 18:56:29 WARN Utils: Your hostname, oussama-pc resolves to a loopback address: 127.0.1.1; using 192.168.1.15 instead (on interface wlp3s0)\n",
      "22/02/01 18:56:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/01 18:56:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Recommender-app').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"book_id\", IntegerType(), True),\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True)])\n",
    "\n",
    "\n",
    "ratings = spark.read.csv(\"../data/books_ratings.csv\", header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|book_id|user_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    314|   5.0|\n",
      "|      1|    439|   3.0|\n",
      "|      1|    588|   5.0|\n",
      "|      1|   1169|   4.0|\n",
      "|      1|   1185|   4.0|\n",
      "|      1|   2077|   4.0|\n",
      "|      1|   2487|   4.0|\n",
      "|      1|   2900|   5.0|\n",
      "|      1|   3662|   4.0|\n",
      "|      1|   3922|   5.0|\n",
      "|      1|   5379|   5.0|\n",
      "|      1|   5461|   3.0|\n",
      "|      1|   5885|   5.0|\n",
      "|      1|   6630|   5.0|\n",
      "|      1|   7563|   3.0|\n",
      "|      1|   9246|   1.0|\n",
      "|      1|  10140|   4.0|\n",
      "|      1|  10146|   5.0|\n",
      "|      1|  10246|   4.0|\n",
      "|      1|  10335|   4.0|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"book_id\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/01 13:04:33 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 5, schema size: 4\n",
      "CSV file: file:///home/oussama/Desktop/workspace/matrix_factorization_recommender/data/books_ratings.csv\n",
      "[Stage 71:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 2.225046600971715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# predictions = model.transform(test)\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "#                                 predictionCol=\"prediction\")\n",
    "# rmse = evaluator.evaluate(predictions)\n",
    "# print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oussama/.local/share/virtualenvs/matrix_factorization_recommender-qyAKTrSQ/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# movieRecs = model.recommendForAllItems(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:=====================================================> (98 + 2) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|book_id|    recommendations|\n",
      "+-------+-------------------+\n",
      "|      1|         [{0, 0.0}]|\n",
      "|     12|[{1775, 5.1165895}]|\n",
      "|     13|  [{58, 10.170677}]|\n",
      "|     22| [{545, 3.8608067}]|\n",
      "|     26| [{329, 5.6786933}]|\n",
      "|     27|         [{0, 0.0}]|\n",
      "|     28|  [{58, 12.186274}]|\n",
      "|     31|  [{58, 7.4835396}]|\n",
      "|     34|         [{0, 0.0}]|\n",
      "|     44|         [{0, 0.0}]|\n",
      "|     47|  [{181, 8.949086}]|\n",
      "|     52|[{1249, 4.8477545}]|\n",
      "|     53|[{1760, 14.496603}]|\n",
      "|     65|         [{0, 0.0}]|\n",
      "|     76|         [{0, 0.0}]|\n",
      "|     78|   [{509, 9.35182}]|\n",
      "|     81|         [{0, 0.0}]|\n",
      "|     85| [{545, 6.4346776}]|\n",
      "|     91|         [{0, 0.0}]|\n",
      "|     93|[{1111, 10.883413}]|\n",
      "+-------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# movieRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_user_0 = pd.DataFrame([0], columns=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id\n",
       "0        0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oussama/.local/share/virtualenvs/matrix_factorization_recommender-qyAKTrSQ/lib/python3.9/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_0_ratings = model.recommendForUserSubset(spark.createDataFrame(pd.DataFrame([0], columns=['user_id'])), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "user_0_ratings.select(\"user_id\", explode(\"recommendations\")\n",
    "  .alias(\"recommendation\")).select(\"user_id\", \"recommendation.*\").drop('user_id').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.715402603149414"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_0_ratings.select(\"recommendations.book_id\", \"recommendations.rating\").first().rating[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302773"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.select('book_id').dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "#from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "\n",
    "df = pd.read_csv(\"../data/books_ratings.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "N = len(df['user_id'].unique())\n",
    "M = len(df['book_id'].unique())\n",
    "\n",
    "        # Map Ids to indices\n",
    "user_mapper = dict(zip(np.unique(df[\"user_id\"]), list(range(N))))\n",
    "book_mapper = dict(zip(np.unique(df[\"book_id\"]), list(range(M))))\n",
    "\n",
    "        # Map indices to IDs\n",
    "user_inv_mapper = dict(zip(list(range(N)), np.unique(df[\"user_id\"])))\n",
    "book_inv_mapper = dict(zip(list(range(M)), np.unique(df[\"book_id\"])))\n",
    "\n",
    "user_index = [user_mapper[i] for i in df['user_id']]\n",
    "book_index = [book_mapper[i] for i in df['book_id']]\n",
    "\n",
    "X = csr_matrix((df[\"rating\"], (user_index, book_index)), shape=(N, M))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<10000x53424 sparse matrix of type '<class 'numpy.int64'>'\n\twith 979478 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_books(user_id, k, metric='cosine', show_distance=False):\n",
    "\n",
    "        neighbour_ids = []\n",
    "\n",
    "        book_ind = user_mapper[user_id]\n",
    "        book_vec = X[book_ind]\n",
    "        k+=1\n",
    "        kNN = NearestNeighbors(n_neighbors=k, algorithm=\"brute\", metric=metric)\n",
    "        kNN.fit(X)\n",
    "        book_vec = book_vec.reshape(1,-1)\n",
    "        neighbour = kNN.kneighbors(book_vec, return_distance=show_distance)\n",
    "        for i in range(0,k):\n",
    "            n = neighbour.item(i)\n",
    "            neighbour_ids.append(user_inv_mapper[n])\n",
    "        neighbour_ids.pop(0)\n",
    "        return neighbour_ids\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}